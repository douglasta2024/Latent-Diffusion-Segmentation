{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/kgong/douglas.ta/CV/lib64/python3.11/site-packages/ignite/handlers/checkpoint.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import sys\n",
    "import tempfile\n",
    "import nibabel as nb\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.data import ArrayDataset, DataLoader, CacheDataset, ThreadDataLoader, decollate_batch\n",
    "from monai.handlers import (\n",
    "    MeanDice,\n",
    "    StatsHandler,\n",
    "    TensorBoardImageHandler,\n",
    "    TensorBoardStatsHandler,\n",
    ")\n",
    "from monai.losses import DiceLoss\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    RandSpatialCrop,\n",
    "    RandShiftIntensity,\n",
    "    RandFlip,\n",
    "    RandRotate90,\n",
    "    RandCropByPosNegLabel,\n",
    "    LoadImage,\n",
    "    ScaleIntensityRange,\n",
    "    CropForeground,\n",
    "    Orientation,\n",
    "    Spacing,\n",
    "    EnsureType\n",
    ")\n",
    "from monai.utils import first\n",
    "\n",
    "import ignite\n",
    "from ignite.handlers import EarlyStopping\n",
    "from ignite.engine import Events\n",
    "from ignite.metrics import Loss\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "root_dir = os.getcwd()\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "\n",
    "cropped_images = sorted(glob.glob(pathname=os.path.join(root_dir, \"cropped_data\", \"volume-*.nii\")))\n",
    "cropped_segs = sorted(glob.glob(pathname=os.path.join(root_dir, \"cropped_data\", \"segmentation-*.nii\")))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_range():\n",
    "#     amax = -1000\n",
    "#     amin = 1000\n",
    "#     for idx in range(len(cropped_images)):\n",
    "#         img = nb.load(cropped_images[idx])\n",
    "#         img = torch.from_numpy(img.get_fdata())\n",
    "#         min_value = torch.min(img)\n",
    "#         max_value = torch.max(img)\n",
    "#         if min_value < amin:\n",
    "#             amin = min_value\n",
    "#         if max_value > amax:\n",
    "#             amax = max_value\n",
    "#     return amax.item(), amin.item()\n",
    "\n",
    "# amax, amin = find_range()\n",
    "# print(amax, amin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import measure\n",
    "\n",
    "# # function used to find the minimum heights for the tumors\n",
    "# def find_heights():\n",
    "#     results = {}\n",
    "#     for idx in range(len(segs)):\n",
    "#         seg = nb.load(segs[idx])\n",
    "#         seg = torch.from_numpy(seg.get_fdata())\n",
    "#         labeled_mask_3d = measure.label(seg, connectivity=3)\n",
    "#         regions_3d = measure.regionprops(labeled_mask_3d)\n",
    "\n",
    "#         lowest_z = 1000\n",
    "#         highest_z = 0\n",
    "#         for region in regions_3d:\n",
    "#             low_z = region.bbox[2]\n",
    "#             high_z = region.bbox[5]\n",
    "#             if lowest_z > low_z:\n",
    "#                 lowest_z = low_z\n",
    "#             if highest_z < high_z:\n",
    "#                 highest_z = high_z\n",
    "#         results[idx] = (lowest_z, highest_z)\n",
    "#     return results\n",
    "\n",
    "# results = find_heights()\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def CropZ(idx):\n",
    "#     #for idx in range(len(segs)):\n",
    "#     img = nb.load(images[idx])\n",
    "#     img_data = img.get_fdata()\n",
    "#     seg = nb.load(segs[idx])\n",
    "#     seg_data = seg.get_fdata()\n",
    "#     low, high = results[idx]\n",
    "#     if (high - low) < 96:   \n",
    "#         mid = high - low\n",
    "#         high = mid + 48 # 48 is half the size of the randspatialcrop\n",
    "#         low = mid - 48\n",
    "#         # condition if low goes out of bounds\n",
    "#         if low < 0:\n",
    "#             high = high - low\n",
    "#             low = 0\n",
    "#         img_data = img_data[:, :,low:high]\n",
    "#         seg_data = seg_data[:, :,low:high]\n",
    "#         cropped_img = nb.Nifti1Image(img_data, img.affine)\n",
    "#         cropped_seg = nb.Nifti1Image(seg_data, seg.affine)        \n",
    "#         nb.save(cropped_img, os.path.join(root_dir, \"cropped_data\", f\"volume-{idx}.nii\"))\n",
    "#         nb.save(cropped_seg, os.path.join(root_dir, \"cropped_data\", f\"segmentation-{idx}.nii\"))  \n",
    "#         print(f\"Img Shape: {img_data.shape} | Seg Shape: {seg_data.shape}, | Low: {low} | High: {high}\")\n",
    "#     else:\n",
    "#         img_data = img_data[:, :,low:high]\n",
    "#         seg_data = seg_data[:, :,low:high]\n",
    "#         cropped_img = nb.Nifti1Image(img_data, img.affine)\n",
    "#         cropped_seg = nb.Nifti1Image(seg_data, seg.affine)\n",
    "#         nb.save(cropped_img, os.path.join(root_dir, \"cropped_data\", f\"volume-{idx}.nii\"))\n",
    "#         nb.save(cropped_seg, os.path.join(root_dir, \"cropped_data\", f\"segmentation-{idx}.nii\"))\n",
    "#         print(f\"Img Shape: {img_data.shape} | Seg Shape: {seg_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numbers generated from the function above\n",
    "#amax, amin = 3071.0, -3024.0\n",
    "amin = -22.18\n",
    "amax = 450.0\n",
    "\n",
    "# Define transforms for image and segmentation\n",
    "train_image_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "        ScaleIntensityRange(\n",
    "            a_min=amin,\n",
    "            a_max=amax,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        #CropForeground(source_key=\"image\"),\n",
    "        Orientation(axcodes=\"RAS\"),\n",
    "        Spacing(\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            #mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        RandSpatialCrop(\n",
    "            (64,64,64), \n",
    "            random_size=False\n",
    "        ),\n",
    "        #EnsureType(device=device, track_meta=False),\n",
    "        # RandCropByPosNegLabel(            \n",
    "        #     spatial_size=(64, 64, 64),\n",
    "        #     pos=1,\n",
    "        #     neg=0,\n",
    "        #     num_samples=1,\n",
    "        #     image_threshold=0,\n",
    "        # ),\n",
    "        RandFlip(            \n",
    "            spatial_axis=[0],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlip(            \n",
    "            spatial_axis=[1],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlip(            \n",
    "            spatial_axis=[2],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandRotate90(           \n",
    "            prob=0.10,\n",
    "            max_k=3,\n",
    "        ),\n",
    "        RandShiftIntensity(        \n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_seg_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "        Orientation(axcodes=\"RAS\"),\n",
    "        Spacing(\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            #mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        #EnsureType(device=device, track_meta=False),\n",
    "        RandSpatialCrop(\n",
    "            (64,64,64), \n",
    "            random_size=False\n",
    "        ),        \n",
    "        # RandCropByPosNegLabel(            \n",
    "        #     spatial_size=(64, 64, 64),\n",
    "        #     pos=1,\n",
    "        #     neg=0,\n",
    "        #     num_samples=1,\n",
    "        #     image_threshold=0,\n",
    "        # ),\n",
    "        RandFlip(            \n",
    "            spatial_axis=[0],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlip(            \n",
    "            spatial_axis=[1],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlip(            \n",
    "            spatial_axis=[2],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandRotate90(           \n",
    "            prob=0.10,\n",
    "            max_k=3,\n",
    "        ),\n",
    "        RandShiftIntensity(        \n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_image_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "        ScaleIntensityRange(\n",
    "            a_min=amin,\n",
    "            a_max=amax,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        #CropForeground(source_key=\"image\"),\n",
    "        # RandCropByPosNegLabel(            \n",
    "        #     spatial_size=(64, 64, 64),\n",
    "        #     pos=1,\n",
    "        #     neg=0,\n",
    "        #     num_samples=1,\n",
    "        #     image_threshold=0,\n",
    "        # ),\n",
    "        Orientation(axcodes=\"RAS\"),\n",
    "        Spacing(\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            #mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        RandSpatialCrop(\n",
    "            (64,64,64), \n",
    "            random_size=False\n",
    "        ),        \n",
    "        #EnsureType(device=device, track_meta=False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_seg_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "        Orientation(axcodes=\"RAS\"),\n",
    "        Spacing(\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            #mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        RandSpatialCrop(\n",
    "            (64,64,64), \n",
    "            random_size=False\n",
    "        ),    \n",
    "        #EnsureType(device=device, track_meta=False),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_folder_contents(folder_path):\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"The folder {folder_path} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    # Loop through each item in the folder\n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        \n",
    "        # Check if it's a file or directory and delete accordingly\n",
    "        if os.path.isfile(item_path) or os.path.islink(item_path):\n",
    "            os.unlink(item_path)  # Remove file or symbolic link\n",
    "        elif os.path.isdir(item_path):\n",
    "            shutil.rmtree(item_path)  # Remove directory and all contents\n",
    "            \n",
    "    print(f\"Contents of the folder '{folder_path}' have been deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the folder 'logs' have been deleted.\n"
     ]
    }
   ],
   "source": [
    "clear_folder_contents(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dict = []\n",
    "# val_dict = []\n",
    "# test_dict = []\n",
    "\n",
    "# for idx in range(len(cropped_images)):\n",
    "#     if idx < 20:\n",
    "#         temp = {\"image\": cropped_images[idx], \"seg\": cropped_segs[idx]}\n",
    "#         train_dict.append(temp)\n",
    "#     elif idx < 24:\n",
    "#         temp = {\"image\": cropped_images[idx], \"seg\": cropped_segs[idx]}\n",
    "#         val_dict.append(temp)\n",
    "#     else:\n",
    "#         temp = {\"image\": cropped_images[idx], \"seg\": cropped_segs[idx]}\n",
    "#         test_dict.append(temp)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNet, DiceLoss and Adam optimizer\n",
    "net = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    #channels=(32, 64, 128, 256, 512),\n",
    "    #channels=(64,128,256,512,1024),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "\n",
    "loss = DiceLoss()\n",
    "lr = 1e-3\n",
    "opt = torch.optim.Adam(net.parameters(), lr)\n",
    "scheduler = ReduceLROnPlateau(opt, mode='min', patience=6, factor=0.1)\n",
    "\n",
    "# create a training data loader\n",
    "train, seg_train = cropped_images[:20], cropped_segs[:20]\n",
    "val, seg_val = cropped_images[20:24], cropped_segs[20:24]\n",
    "test, seg_test = cropped_images[24:], cropped_segs[24:]\n",
    "\n",
    "train_ds = ArrayDataset(img=train, img_transform=val_image_transforms, seg=seg_train, seg_transform=val_seg_transforms)\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=5,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "val_ds = ArrayDataset(img=val, img_transform=val_image_transforms, seg=seg_val, seg_transform=val_seg_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=2, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "test_ds = ArrayDataset(img=test, img_transform=val_image_transforms, seg=seg_test, seg_transform=val_seg_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=2, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = ignite.engine.create_supervised_trainer(net, opt, loss, device, False)\n",
    "\n",
    "# optional section for checkpoint and tensorboard logging\n",
    "# adding checkpoint handler to save models (network\n",
    "# params and optimizer stats) during training\n",
    "log_dir = os.path.join(root_dir, \"logs\")\n",
    "checkpoint_handler = ignite.handlers.ModelCheckpoint(log_dir, \"net\", n_saved=10, require_empty=False)\n",
    "trainer.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    handler=checkpoint_handler,\n",
    "    to_save={\"net\": net, \"opt\": opt},\n",
    ")\n",
    "\n",
    "# StatsHandler prints loss at every iteration\n",
    "# user can also customize print functions and can use output_transform to convert\n",
    "# engine.state.output if it's not a loss value\n",
    "train_stats_handler = StatsHandler(name=\"trainer\", output_transform=lambda x: x)\n",
    "train_stats_handler.attach(trainer)\n",
    "\n",
    "# TensorBoardStatsHandler plots loss at every iteration\n",
    "train_tensorboard_stats_handler = TensorBoardStatsHandler(log_dir=log_dir, output_transform=lambda x: x)\n",
    "train_tensorboard_stats_handler.attach(trainer)\n",
    "\n",
    "# optional section for model validation during training\n",
    "validation_every_n_epochs = 1\n",
    "\n",
    "# Set parameters for validation\n",
    "metric_name = \"Mean_Dice\"\n",
    "metric_loss = \"Loss\"\n",
    "\n",
    "# add evaluation metric to the evaluator engine\n",
    "val_metrics = {\n",
    "    metric_name: MeanDice(),\n",
    "    metric_loss: Loss(loss)\n",
    "    }\n",
    "post_pred = Compose([Activations(), AsDiscrete(threshold=0.5)])\n",
    "post_label = Compose([AsDiscrete(threshold=0.5)])\n",
    "\n",
    "# Ignite evaluator expects batch=(img, seg) and\n",
    "# returns output=(y_pred, y) at every iteration,\n",
    "# user can add output_transform to return other values\n",
    "evaluator = ignite.engine.create_supervised_evaluator(\n",
    "    net,\n",
    "    val_metrics,\n",
    "    device,\n",
    "    True,\n",
    "    output_transform=lambda x, y, y_pred: (\n",
    "        [post_pred(i) for i in decollate_batch(y_pred)],\n",
    "        [post_label(i) for i in decollate_batch(y)],\n",
    "    ),\n",
    ")\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED(every=validation_every_n_epochs))\n",
    "def run_validation(engine):\n",
    "    evaluator.run(val_loader)\n",
    "\n",
    "# Add stats event handler to print validation stats via evaluator\n",
    "val_stats_handler = StatsHandler(\n",
    "    name=\"evaluator\",\n",
    "    # no need to print loss value, so disable per iteration output\n",
    "    output_transform=lambda x: None,\n",
    "    # fetch global epoch number from trainer\n",
    "    global_epoch_transform=lambda x: trainer.state.epoch,\n",
    ")\n",
    "val_stats_handler.attach(evaluator)\n",
    "\n",
    "# add handler to record metrics to TensorBoard at every validation epoch\n",
    "val_tensorboard_stats_handler = TensorBoardStatsHandler(\n",
    "    log_dir=log_dir,\n",
    "    # no need to plot loss value, so disable per iteration output\n",
    "    output_transform=lambda x: None,\n",
    "    # fetch global epoch number from trainer\n",
    "    global_epoch_transform=lambda x: trainer.state.epoch,\n",
    ")\n",
    "val_tensorboard_stats_handler.attach(evaluator)\n",
    "\n",
    "# add handler to draw the first image and the corresponding\n",
    "# label and model output in the last batch\n",
    "# here we draw the 3D output as GIF format along Depth\n",
    "# axis, at every validation epoch\n",
    "val_tensorboard_image_handler = TensorBoardImageHandler(\n",
    "    log_dir=log_dir,\n",
    "    batch_transform=lambda batch: (batch[0], batch[1]),\n",
    "    output_transform=lambda output: output[0],\n",
    "    global_iter_transform=lambda x: trainer.state.epoch,\n",
    ")\n",
    "evaluator.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    handler=val_tensorboard_image_handler,\n",
    ")\n",
    "\n",
    "# adding a scheduler to update learning rate\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def update_sheduler(engine):\n",
    "    val_loss = evaluator.state.metrics[metric_loss]\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "\n",
    "def score_function(engine):\n",
    "    # Return the metric you want to monitor \n",
    "    return -engine.state.metrics[metric_loss]  \n",
    "\n",
    "# adding earlystop handler\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=10,  # Number of epochs with no improvement\n",
    "    score_function=score_function,\n",
    "    trainer=trainer  # Trainer to stop when condition is met\n",
    ")\n",
    "\n",
    "# Attach early stopping to the evaluator (usually validation evaluator)\n",
    "evaluator.add_event_handler(Events.EPOCH_COMPLETED, early_stopping)\n",
    "\n",
    "# Define a test evaluator\n",
    "test_evaluator = ignite.engine.create_supervised_evaluator(\n",
    "    net,\n",
    "    metrics={\n",
    "        metric_name: MeanDice(),\n",
    "        metric_loss: Loss(loss)\n",
    "    },\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "@trainer.on(Events.COMPLETED)\n",
    "def evaluate_test_set(engine):\n",
    "    test_evaluator.run(test_loader)\n",
    "    metrics = test_evaluator.state.metrics\n",
    "    print(f\"Test Mean Dice: {metrics[metric_name]:.4f} | Test Loss: {metrics[metric_loss]:.4f}\")\n",
    "\n",
    "save_dir = \"saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "@trainer.on(Events.COMPLETED)\n",
    "def save_model(engine):\n",
    "    model_path = os.path.join(save_dir, \"model.pth\")  # Create full path\n",
    "    torch.save(net.state_dict(), model_path)  # Save model weights\n",
    "    print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-28 16:13:07,424 - INFO - Epoch: 1/32, Iter: 1/4 -- Loss: 0.8883 \n",
      "2024-11-28 16:13:17,364 - INFO - Epoch: 1/32, Iter: 2/4 -- Loss: 0.9974 \n",
      "2024-11-28 16:13:36,301 - INFO - Epoch: 1/32, Iter: 3/4 -- Loss: 0.8953 \n",
      "2024-11-28 16:13:50,436 - INFO - Epoch: 1/32, Iter: 4/4 -- Loss: 0.8943 \n",
      "2024-11-28 16:14:01,313 - INFO - Epoch[1] Metrics -- Loss: 0.8541 Mean_Dice: 0.2917 \n",
      "2024-11-28 16:14:38,153 - INFO - Epoch: 2/32, Iter: 1/4 -- Loss: 0.9902 \n",
      "2024-11-28 16:14:38,182 - INFO - Epoch: 2/32, Iter: 2/4 -- Loss: 0.8244 \n",
      "2024-11-28 16:15:05,015 - INFO - Epoch: 2/32, Iter: 3/4 -- Loss: 0.8343 \n",
      "2024-11-28 16:15:05,044 - INFO - Epoch: 2/32, Iter: 4/4 -- Loss: 0.9706 \n",
      "2024-11-28 16:15:15,617 - INFO - Epoch[2] Metrics -- Loss: 1.0000 Mean_Dice: 0.0000 \n",
      "2024-11-28 16:15:56,307 - INFO - Epoch: 3/32, Iter: 1/4 -- Loss: 0.7483 \n",
      "2024-11-28 16:15:56,337 - INFO - Epoch: 3/32, Iter: 2/4 -- Loss: 1.0000 \n",
      "2024-11-28 16:16:20,251 - INFO - Epoch: 3/32, Iter: 3/4 -- Loss: 0.9337 \n",
      "2024-11-28 16:16:20,278 - INFO - Epoch: 3/32, Iter: 4/4 -- Loss: 0.7618 \n",
      "2024-11-28 16:16:30,870 - INFO - Epoch[3] Metrics -- Loss: 0.8435 Mean_Dice: 0.3131 \n",
      "2024-11-28 16:17:01,647 - INFO - Epoch: 4/32, Iter: 1/4 -- Loss: 1.0000 \n",
      "2024-11-28 16:17:01,676 - INFO - Epoch: 4/32, Iter: 2/4 -- Loss: 0.6258 \n",
      "2024-11-28 16:17:29,087 - INFO - Epoch: 4/32, Iter: 3/4 -- Loss: 0.5479 \n",
      "2024-11-28 16:17:35,136 - INFO - Epoch: 4/32, Iter: 4/4 -- Loss: 0.5734 \n",
      "2024-11-28 16:17:45,734 - INFO - Epoch[4] Metrics -- Loss: 0.5746 Mean_Dice: 0.5672 \n",
      "2024-11-28 16:18:32,333 - INFO - Epoch: 5/32, Iter: 1/4 -- Loss: 0.8537 \n",
      "2024-11-28 16:18:32,358 - INFO - Epoch: 5/32, Iter: 2/4 -- Loss: 0.7567 \n",
      "2024-11-28 16:19:18,607 - INFO - Epoch: 5/32, Iter: 3/4 -- Loss: 0.7099 \n",
      "2024-11-28 16:19:18,636 - INFO - Epoch: 5/32, Iter: 4/4 -- Loss: 0.5552 \n",
      "2024-11-28 16:19:36,181 - INFO - Epoch[5] Metrics -- Loss: 0.7886 Mean_Dice: 0.8458 \n",
      "2024-11-28 16:20:12,404 - INFO - Epoch: 6/32, Iter: 1/4 -- Loss: 0.6313 \n",
      "2024-11-28 16:20:12,434 - INFO - Epoch: 6/32, Iter: 2/4 -- Loss: 0.6985 \n",
      "2024-11-28 16:21:14,475 - INFO - Epoch: 6/32, Iter: 3/4 -- Loss: 0.7429 \n",
      "2024-11-28 16:21:14,504 - INFO - Epoch: 6/32, Iter: 4/4 -- Loss: 1.0000 \n",
      "2024-11-28 16:21:24,819 - INFO - Epoch[6] Metrics -- Loss: 0.8550 Mean_Dice: 0.5800 \n",
      "2024-11-28 16:21:51,821 - INFO - Epoch: 7/32, Iter: 1/4 -- Loss: 0.2620 \n",
      "2024-11-28 16:21:59,884 - INFO - Epoch: 7/32, Iter: 2/4 -- Loss: 0.9290 \n",
      "2024-11-28 16:22:20,749 - INFO - Epoch: 7/32, Iter: 3/4 -- Loss: 0.7573 \n",
      "2024-11-28 16:22:28,490 - INFO - Epoch: 7/32, Iter: 4/4 -- Loss: 0.6774 \n",
      "2024-11-28 16:22:38,854 - INFO - Epoch[7] Metrics -- Loss: 0.9903 Mean_Dice: 0.0194 \n",
      "2024-11-28 16:23:10,496 - INFO - Epoch: 8/32, Iter: 1/4 -- Loss: 0.6693 \n",
      "2024-11-28 16:23:10,524 - INFO - Epoch: 8/32, Iter: 2/4 -- Loss: 1.0000 \n",
      "2024-11-28 16:23:42,990 - INFO - Epoch: 8/32, Iter: 3/4 -- Loss: 0.5761 \n",
      "2024-11-28 16:23:43,018 - INFO - Epoch: 8/32, Iter: 4/4 -- Loss: 0.5970 \n",
      "2024-11-28 16:23:53,311 - INFO - Epoch[8] Metrics -- Loss: 0.7924 Mean_Dice: 0.2768 \n",
      "2024-11-28 16:24:29,515 - INFO - Epoch: 9/32, Iter: 1/4 -- Loss: 1.0000 \n",
      "2024-11-28 16:24:29,545 - INFO - Epoch: 9/32, Iter: 2/4 -- Loss: 0.6540 \n",
      "2024-11-28 16:24:54,293 - INFO - Epoch: 9/32, Iter: 3/4 -- Loss: 0.9999 \n",
      "2024-11-28 16:24:54,316 - INFO - Epoch: 9/32, Iter: 4/4 -- Loss: 0.6944 \n",
      "2024-11-28 16:25:04,649 - INFO - Epoch[9] Metrics -- Loss: 0.8378 Mean_Dice: 0.6486 \n",
      "2024-11-28 16:25:38,906 - INFO - Epoch: 10/32, Iter: 1/4 -- Loss: 0.7611 \n",
      "2024-11-28 16:25:38,936 - INFO - Epoch: 10/32, Iter: 2/4 -- Loss: 0.0341 \n",
      "2024-11-28 16:26:09,680 - INFO - Epoch: 10/32, Iter: 3/4 -- Loss: 0.6773 \n",
      "2024-11-28 16:26:09,708 - INFO - Epoch: 10/32, Iter: 4/4 -- Loss: 0.4139 \n",
      "2024-11-28 16:26:20,036 - INFO - Epoch[10] Metrics -- Loss: 0.9549 Mean_Dice: 0.0901 \n",
      "2024-11-28 16:26:48,599 - INFO - Epoch: 11/32, Iter: 1/4 -- Loss: 0.9608 \n",
      "2024-11-28 16:26:48,628 - INFO - Epoch: 11/32, Iter: 2/4 -- Loss: 0.7760 \n",
      "2024-11-28 16:27:20,372 - INFO - Epoch: 11/32, Iter: 3/4 -- Loss: 0.2587 \n",
      "2024-11-28 16:27:20,392 - INFO - Epoch: 11/32, Iter: 4/4 -- Loss: 1.0000 \n",
      "2024-11-28 16:27:40,051 - INFO - Epoch[11] Metrics -- Loss: 0.7871 Mean_Dice: 0.4258 \n",
      "2024-11-28 16:28:17,783 - INFO - Epoch: 12/32, Iter: 1/4 -- Loss: 0.4818 \n",
      "2024-11-28 16:28:26,536 - INFO - Epoch: 12/32, Iter: 2/4 -- Loss: 0.6782 \n",
      "2024-11-28 16:28:53,981 - INFO - Epoch: 12/32, Iter: 3/4 -- Loss: 0.2926 \n",
      "2024-11-28 16:28:55,600 - INFO - Epoch: 12/32, Iter: 4/4 -- Loss: 0.7479 \n",
      "2024-11-28 16:29:16,315 - INFO - Epoch[12] Metrics -- Loss: 0.7597 Mean_Dice: 0.3203 \n",
      "2024-11-28 16:29:44,755 - INFO - Epoch: 13/32, Iter: 1/4 -- Loss: 0.1413 \n",
      "2024-11-28 16:29:59,670 - INFO - Epoch: 13/32, Iter: 2/4 -- Loss: 1.0000 \n",
      "2024-11-28 16:30:12,657 - INFO - Epoch: 13/32, Iter: 3/4 -- Loss: 0.6976 \n",
      "2024-11-28 16:30:34,555 - INFO - Epoch: 13/32, Iter: 4/4 -- Loss: 0.8901 \n",
      "2024-11-28 16:30:45,494 - INFO - Epoch[13] Metrics -- Loss: 0.8166 Mean_Dice: 0.7334 \n",
      "2024-11-28 16:31:16,675 - INFO - Epoch: 14/32, Iter: 1/4 -- Loss: 1.0000 \n",
      "2024-11-28 16:31:28,625 - INFO - Epoch: 14/32, Iter: 2/4 -- Loss: 0.9855 \n",
      "2024-11-28 16:31:44,272 - INFO - Epoch: 14/32, Iter: 3/4 -- Loss: 0.7729 \n",
      "2024-11-28 16:31:55,016 - INFO - Epoch: 14/32, Iter: 4/4 -- Loss: 0.7761 \n",
      "2024-11-28 16:32:05,338 - INFO - Epoch[14] Metrics -- Loss: 0.9774 Mean_Dice: 0.0903 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 16:32:05,417 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Dice: 0.0000 | Test Loss: 0.7679\n",
      "Model saved to saved_models/model.pth\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 32\n",
    "state = trainer.run(train_loader, max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
